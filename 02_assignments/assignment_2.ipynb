{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bcac6-5086-4f4e-928a-570a9ff7ae58",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0350-2a17-4e93-8d4c-0b8748fdfc32",
   "metadata": {},
   "source": [
    "As before, if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "We will go through comparable code and concepts in the live learning sessions. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that no outside searches are required by the assignment!). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to office hours, work periods or share with your peers on Slack. We will work with you through the issue.\n",
    "\n",
    "If you like, you may collaborate with others in the cohort. If you choose to do so, please indicate with whom you have worked with in your pull request by tagging their GitHub username. Separate submissions are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffd43063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59e07e-6abb-4f6c-9c1b-760b11626ce7",
   "metadata": {},
   "source": [
    "### Question 1: Classification using KNN\n",
    "\n",
    "We'll now use the `Caravan` dataset from the `ISLP` package. (You may use `Caravan.describe()` to review details of the dataset.) In this dataset, the response variable of interest is `Purchase`, which indicates if a given customer purchased a caravan insurance policy. We will simultaneously use all other variables in the dataset to predict the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6449268e-0e33-4976-83cf-5ada4b29597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MOSTYPE     MAANTHUI      MGEMOMV     MGEMLEEF     MOSHOOFD  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean     24.253349     1.110615     2.678805     2.991240     5.773617   \n",
      "std      12.846706     0.405842     0.789835     0.814589     2.856760   \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
      "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
      "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
      "max      41.000000    10.000000     5.000000     6.000000    10.000000   \n",
      "\n",
      "            MGODRK       MGODPR       MGODOV       MGODGE       MRELGE  ...  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  ...   \n",
      "mean      0.696496     4.626932     1.069907     3.258502     6.183442  ...   \n",
      "std       1.003234     1.715843     1.017503     1.597647     1.909482  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     4.000000     0.000000     2.000000     5.000000  ...   \n",
      "50%       0.000000     5.000000     1.000000     3.000000     6.000000  ...   \n",
      "75%       1.000000     6.000000     2.000000     4.000000     7.000000  ...   \n",
      "max       9.000000     9.000000     5.000000     9.000000     9.000000  ...   \n",
      "\n",
      "            ALEVEN     APERSONG      AGEZONG      AWAOREG       ABRAND  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean      0.076606     0.005325     0.006527     0.004638     0.570079   \n",
      "std       0.377569     0.072782     0.080532     0.077403     0.562058   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "max       8.000000     1.000000     1.000000     2.000000     7.000000   \n",
      "\n",
      "           AZEILPL     APLEZIER       AFIETS      AINBOED     ABYSTAND  \n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  \n",
      "mean      0.000515     0.006012     0.031776     0.007901     0.014256  \n",
      "std       0.022696     0.081632     0.210986     0.090463     0.119996  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "max       1.000000     2.000000     3.000000     2.000000     2.000000  \n",
      "\n",
      "[8 rows x 85 columns]\n",
      "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
      "0       33         1        3         2         8       0       5       1   \n",
      "1       37         1        2         2         8       1       4       1   \n",
      "2       37         1        2         2         8       0       4       2   \n",
      "3        9         1        3         3         3       2       3       2   \n",
      "4       40         1        4         2        10       1       4       1   \n",
      "\n",
      "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
      "0       3       7  ...         0        0        0       1        0         0   \n",
      "1       4       6  ...         0        0        0       1        0         0   \n",
      "2       4       3  ...         0        0        0       1        0         0   \n",
      "3       4       5  ...         0        0        0       1        0         0   \n",
      "4       4       7  ...         0        0        0       1        0         0   \n",
      "\n",
      "   AFIETS  AINBOED  ABYSTAND  Purchase  \n",
      "0       0        0         0        No  \n",
      "1       0        0         0        No  \n",
      "2       0        0         0        No  \n",
      "3       0        0         0        No  \n",
      "4       0        0         0        No  \n",
      "\n",
      "[5 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the \"Caravan\" dataset using the \"load_data\" function from the ISLP package\n",
    "Caravan = load_data('Caravan')\n",
    "\n",
    "# Add your code here\n",
    "print(Caravan.describe())\n",
    "print(Caravan.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60779b-cba9-4972-aeeb-b89e65fda11c",
   "metadata": {},
   "source": [
    "Before fitting any model, it is essential to understand our data. Answer the following questions about the `Caravan` dataset (Hint: use `print` and `describe`):  \n",
    "_(i)_ How many observations (rows) does the dataset contain?    \n",
    "_(ii)_ How many variables (columns) does the dataset contain?    \n",
    "_(iii)_ What 'variable' type is the response variable `Purchase` (e.g., 'character', 'factor', 'numeric', etc)? What are the 'levels' of the variable?    \n",
    "_(iv)_ How many predictor variables do we have (Hint: all variables other than `Purchase`)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a3a8ec5-98e4-431d-967b-ae1482127de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i) The dataset contains 5822 observations (rows).\n",
      "(ii) The dataset contains 86 variables (columns).\n",
      "(iii) The response variable 'Purchase' is of type 'object'. It has the following levels: ['No' 'Yes'].\n",
      "(iv) There are 85 predictor variables.\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "# (i) How many observations (rows) does the dataset contain?\n",
    "num_rows = Caravan.shape[0]\n",
    "print(f\"(i) The dataset contains {num_rows} observations (rows).\")\n",
    "\n",
    "# (ii) How many variables (columns) does the dataset contain?\n",
    "num_columns = Caravan.shape[1]\n",
    "print(f\"(ii) The dataset contains {num_columns} variables (columns).\")\n",
    "\n",
    "# (iii) What 'variable' type is the response variable `Purchase` (e.g., 'character', 'factor', 'numeric', etc)? What are the 'levels' of the variable?\n",
    "purchase_type = Caravan['Purchase'].dtype\n",
    "purchase_levels = Caravan['Purchase'].unique()\n",
    "print(f\"(iii) The response variable 'Purchase' is of type '{purchase_type}'. It has the following levels: {purchase_levels}.\")\n",
    "\n",
    "# (iv) How many predictor variables do we have (Hint: all variables other than `Purchase`)?\n",
    "num_predictors = num_columns - 1\n",
    "print(f\"(iv) There are {num_predictors} predictor variables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d31d9",
   "metadata": {},
   "source": [
    "Next, we must preform 'pre-processing' or 'data munging', to prepare our data for classification/prediction. For KNN, there are three essential steps. A first essential step is to 'standardize' the predictor variables. We can achieve this using the `scaler` method, provided as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c2901b1-82ce-4729-88d9-7d9985336221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MOSTYPE  MAANTHUI   MGEMOMV  MGEMLEEF  MOSHOOFD    MGODRK    MGODPR  \\\n",
      "0  0.680906  -0.27258  0.406697 -1.216964  0.779405 -0.694311  0.217444   \n",
      "1  0.992297  -0.27258 -0.859500 -1.216964  0.779405  0.302552 -0.365410   \n",
      "2  0.992297  -0.27258 -0.859500 -1.216964  0.779405 -0.694311 -0.365410   \n",
      "3 -1.187437  -0.27258  0.406697  0.010755 -0.970980  1.299414 -0.948264   \n",
      "4  1.225840  -0.27258  1.672893 -1.216964  1.479559  0.302552 -0.365410   \n",
      "\n",
      "     MGODOV    MGODGE    MRELGE  ...   ALEVEN  APERSONG   AGEZONG  AWAOREG  \\\n",
      "0 -0.068711 -0.161816  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "1 -0.068711  0.464159 -0.096077  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "2  0.914172  0.464159 -1.667319  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "3  0.914172  0.464159 -0.619824  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "4 -0.068711  0.464159  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "\n",
      "     ABRAND   AZEILPL  APLEZIER   AFIETS   AINBOED  ABYSTAND  \n",
      "0  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "1  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "2  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "3  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "4  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "\n",
      "[5 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select predictors (excluding the 86th column)\n",
    "predictors = Caravan.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b3eaa-698e-4190-97cd-098e0e3d532e",
   "metadata": {},
   "source": [
    "_(v)_ Why is it important to standardize the predictor variables?  \n",
    "_(vi)_ Why did we elect not to standard our response variable `Purchase`?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2b16a",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "(v) Because it ensures that all variables contribute equally to the distance calculations used in KNN. KNN is a distance-based algorithm, meaning it relies on the Euclidean distance (or other distance metrics) to determine the nearest neighbors. If the predictor variables are on different scales, variables with larger scales will dominate the distance calculation, leading to biased results. Standardizing\n",
    "\n",
    "(vi) The response variable Purchase is a categorical variable that indicates whether a customer purchased a caravan insurance policy ('Yes' or 'No'). Standardizing a categorical variable does not make sense because the values are not on a numerical scale that would benefit from scaling. The KNN algorithm treats the response variable as a label, not a feature, so it does not require or benefit from standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffb22f",
   "metadata": {},
   "source": [
    "\n",
    "_(vii)_ A second essential step is to set a random seed. Do so below (Hint: use the `random.seed` function). Why is setting a seed important? Is the particular seed value important? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ae50a",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "(vii) Setting a seed is important because it allows for the reproducibility of results. In machine learning and data science, many algorithms and processes involve some form of randomness, such as splitting data into training and test sets, initializing parameters, or performing random sampling. By setting a seed, you ensure that these random processes produce the same results each time the code is run. This is crucial for debugging, comparing models, and sharing results with others.\n",
    "\n",
    "The specific value of the seed itself is not important. What is important is that you use a seed consistently. Different seed values will produce different sequences of random numbers, but as long as you use the same seed, you will get the same sequence of random numbers each time you run the code. Therefore, the particular seed value is arbitrary; it can be any integer. The key is to use the same seed if you want to reproduce the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4862c6-ed52-402f-b3f0-fead91646033",
   "metadata": {},
   "source": [
    "_(viii)_ A third essential step is to split our standardized data into separate training and testing sets. We will split into 75% training and 25% testing. The provided code randomly partitions our data, and creates linked training sets for the predictors and response variables. Extend the code to create a non-overlapping test set for the predictors and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbe9f219-571b-476b-9f5b-b47431c803b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MOSTYPE  MAANTHUI   MGEMOMV  MGEMLEEF  MOSHOOFD    MGODRK    MGODPR  \\\n",
      "0  0.680906  -0.27258  0.406697 -1.216964  0.779405 -0.694311  0.217444   \n",
      "1  0.992297  -0.27258 -0.859500 -1.216964  0.779405  0.302552 -0.365410   \n",
      "2  0.992297  -0.27258 -0.859500 -1.216964  0.779405 -0.694311 -0.365410   \n",
      "3 -1.187437  -0.27258  0.406697  0.010755 -0.970980  1.299414 -0.948264   \n",
      "4  1.225840  -0.27258  1.672893 -1.216964  1.479559  0.302552 -0.365410   \n",
      "\n",
      "     MGODOV    MGODGE    MRELGE  ...   ALEVEN  APERSONG   AGEZONG  AWAOREG  \\\n",
      "0 -0.068711 -0.161816  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "1 -0.068711  0.464159 -0.096077  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "2  0.914172  0.464159 -1.667319  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "3  0.914172  0.464159 -0.619824  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "4 -0.068711  0.464159  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "\n",
      "     ABRAND   AZEILPL  APLEZIER   AFIETS   AINBOED  ABYSTAND  \n",
      "0  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "1  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "2  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "3  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "4  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "\n",
      "[5 rows x 85 columns]\n",
      "Training set X shape: (4411, 85)\n",
      "Training set Y shape: (4411,)\n",
      "Testing set X shape: (1411, 85)\n",
      "Testing set Y shape: (1411,)\n"
     ]
    }
   ],
   "source": [
    "# Select predictors (excluding the 86th column)\n",
    "predictors = Caravan.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())\n",
    "\n",
    "# Create a random vector of True and False values for splitting\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = Caravan.loc[split, 'Purchase']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = Caravan.loc[~split, 'Purchase']\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(f\"Training set X shape: {training_X.shape}\")\n",
    "print(f\"Training set Y shape: {training_Y.shape}\")\n",
    "print(f\"Testing set X shape: {testing_X.shape}\")\n",
    "print(f\"Testing set Y shape: {testing_Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f16dbc-0be6-4cc8-b2c4-edab7042c702",
   "metadata": {},
   "source": [
    "_(ix)_ We are finally set to fit the KNN model. In Python, we can use the `KNeighborsClassifier()` function. Fit the KNN with k=1. (You may review arguments to knn by typing `help(knn.fit)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6a117de-279b-4320-b64e-4051ba2887d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1233  102]\n",
      " [  65   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.92      0.94      1335\n",
      "         Yes       0.10      0.14      0.12        76\n",
      "\n",
      "    accuracy                           0.88      1411\n",
      "   macro avg       0.52      0.53      0.53      1411\n",
      "weighted avg       0.90      0.88      0.89      1411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Fit the KNN model with k=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(training_X, training_Y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = knn.predict(testing_X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(testing_Y, predictions))\n",
    "print(classification_report(testing_Y, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33a32a-95d3-49db-bb1b-663360267b18",
   "metadata": {},
   "source": [
    "Using your fit model, answer the following questions:   \n",
    "_(x)_ What is the prediction accuracy? (Hint: use the `score` method, and compare your model to `testing_Y`)  \n",
    "_(xi)_ What is the predictor error ? (Hint: compute it from the accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74dbe6c4-1a4d-4f06-9e2e-597da03952ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.8816442239546421\n"
     ]
    }
   ],
   "source": [
    "# prediction accuracy rate\n",
    "accuracy = knn.score(testing_X, testing_Y)\n",
    "print(f\"Prediction accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9384d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor error: 0.11835577604535785\n"
     ]
    }
   ],
   "source": [
    "# prediction error rate\n",
    "predictor_error = 1 - accuracy\n",
    "print(f\"Predictor error: {predictor_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9342c-9dcd-4f6d-b437-6065417483db",
   "metadata": {},
   "source": [
    "_(xii)_ How does this prediction error/accuracy compare to what could be achieved via random guesses? To answer this, consider the percent of customers in the `Caravan` dataset who actually purchase insurance, computed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c89ade30-3465-4104-b300-61d78b319d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of customers who purchase insurance: 5.98%\n",
      "Baseline accuracy (always guessing 'No'): 0.94\n",
      "Baseline predictor error: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of customers who purchase insurance\n",
    "percentage_purchase = (Caravan['Purchase'].eq('Yes').sum() / len(Caravan['Purchase'])) * 100\n",
    "print(f\"Percentage of customers who purchase insurance: {percentage_purchase:.2f}%\")\n",
    "\n",
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = Caravan['Purchase'].eq('No').sum() / len(Caravan['Purchase'])\n",
    "print(f\"Baseline accuracy (always guessing 'No'): {baseline_accuracy:.2f}\")\n",
    "\n",
    "# Calculate the baseline predictor error\n",
    "baseline_error = 1 - baseline_accuracy\n",
    "print(f\"Baseline predictor error: {baseline_error:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556aa17",
   "metadata": {},
   "source": [
    "The KNN model's accuracy (88%) is lower than the baseline accuracy (94%). This suggests that the KNN model with k=1 is not performing better than simply guessing the most frequent class ('No'). The predictor error for the KNN model (12%) is higher than the baseline predictor error (6%), further indicating that the KNN model's performance is not better than the baseline for this dataset. This could be due to the imbalance in the dataset, where the majority class ('No') dominates the predictions. To improve the model, techniques such as balancing the dataset, tuning hyperparameters, or using more advanced models might be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e19b5e-ad65-47f8-a3ef-e0f68a75048e",
   "metadata": {},
   "source": [
    "_(xiii)_ Fit a second KNN model, with $K=3$. Does this model perform better (i.e., have higher accuracy, compared to a random guess)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fedbe4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model with K=3\n",
      "[[1313   22]\n",
      " [  69    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.98      0.97      1335\n",
      "         Yes       0.24      0.09      0.13        76\n",
      "\n",
      "    accuracy                           0.94      1411\n",
      "   macro avg       0.60      0.54      0.55      1411\n",
      "weighted avg       0.91      0.94      0.92      1411\n",
      "\n",
      "Prediction accuracy with K=3: 0.94\n",
      "Predictor error with K=3: 0.06\n",
      "Baseline accuracy (always guessing 'No'): 0.94\n",
      "Baseline predictor error: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Fit the KNN model with k=3\n",
    "knn_k3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_k3.fit(training_X, training_Y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_k3 = knn_k3.predict(testing_X)\n",
    "\n",
    "# Evaluate the model with k=3\n",
    "print(\"KNN Model with K=3\")\n",
    "print(confusion_matrix(testing_Y, predictions_k3))\n",
    "print(classification_report(testing_Y, predictions_k3))\n",
    "\n",
    "# Calculate the prediction accuracy with k=3\n",
    "accuracy_k3 = knn_k3.score(testing_X, testing_Y)\n",
    "print(f\"Prediction accuracy with K=3: {accuracy_k3:.2f}\")\n",
    "\n",
    "# Calculate the predictor error with k=3\n",
    "predictor_error_k3 = 1 - accuracy_k3\n",
    "print(f\"Predictor error with K=3: {predictor_error_k3:.2f}\")\n",
    "\n",
    "# Baseline accuracy\n",
    "baseline_accuracy = Caravan['Purchase'].eq('No').sum() / len(Caravan['Purchase'])\n",
    "print(f\"Baseline accuracy (always guessing 'No'): {baseline_accuracy:.2f}\")\n",
    "\n",
    "# Baseline predictor error\n",
    "baseline_error = 1 - baseline_accuracy\n",
    "print(f\"Baseline predictor error: {baseline_error:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e3e08",
   "metadata": {},
   "source": [
    "The KNN model with K=3 has a prediction accuracy of 94%, which matches the baseline accuracy of always guessing 'No'. This indicates that the KNN model with K=3 performs as well as the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5050f",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "|Criteria            |Complete           |Incomplete          |\n",
    "|--------------------|---------------|--------------|\n",
    "|Classification using KNN|All steps are done correctly and the answers are correct.|At least one step is done incorrectly leading to a wrong answer.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b78bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf69b4d",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/applied_statistical_concepts/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
